{
  "6": {
    "inputs": {
      "text": "A anime clip with a close-up shot of a young girl's hands, gently plucking a vibrant red berry from a bush. Her fingers are slightly stained, and a soft smile begins to form as she brings the berry towards her mouth.",
      "clip": [
        "38",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "ugly, lowres, blurry, motionless, low quality, draft",
      "clip": [
        "38",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "295",
        0
      ],
      "vae": [
        "39",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "30": {
    "inputs": {
      "frame_rate": 16,
      "loop_count": 0,
      "filename_prefix": "Video",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": true,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "8",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine ðŸŽ¥ðŸ…¥ðŸ…—ðŸ…¢"
    }
  },
  "38": {
    "inputs": {
      "clip_name": "forge\\umt5_xxl_fp8_e4m3fn_scaled.safetensors",
      "type": "wan",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "39": {
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "40": {
    "inputs": {
      "width": 960,
      "height": 544,
      "length": 81,
      "batch_size": 1
    },
    "class_type": "EmptyHunyuanLatentVideo",
    "_meta": {
      "title": "EmptyHunyuanLatentVideo"
    }
  },
  "48": {
    "inputs": {
      "shift": 3.0000000000000004,
      "model": [
        "292",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "Shift"
    }
  },
  "291": {
    "inputs": {
      "unet_name": "aniWan2114BFp8E4m3fn_t2v14BGGUFQ4KS.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "Unet Loader (GGUF)"
    }
  },
  "292": {
    "inputs": {
      "lora_name": "Wan21_T2V_14B_lightx2v_cfg_step_distill_lora_rank32.safetensors",
      "strength_model": 1.0000000000000002,
      "model": [
        "294",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "294": {
    "inputs": {
      "sage_attention": "auto",
      "model": [
        "291",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "295": {
    "inputs": {
      "seed": 658045409311828,
      "steps": 5,
      "cfg": 1,
      "nag_scale": 8,
      "nag_tau": 4,
      "nag_alpha": 0.4,
      "nag_sigma_end": 0,
      "sampler_name": "euler",
      "scheduler": "beta",
      "denoise": 1,
      "model": [
        "48",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "nag_negative": [
        "7",
        0
      ],
      "latent_image": [
        "40",
        0
      ]
    },
    "class_type": "KSamplerWithNAG",
    "_meta": {
      "title": "KSamplerWithNAG"
    }
  }
}